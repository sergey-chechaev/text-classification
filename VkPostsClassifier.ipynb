{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "from psycopg2.sql import SQL, Identifier\n",
    "\n",
    "psql_db_name = 'text_classification_db'\n",
    "psql_table_prefix = 'vk_wall_posts'\n",
    "psql_user = 'zhenek'\n",
    "psql_pass = '1'\n",
    "psql_host = '/var/run/postgresql/'\n",
    "max_data_size = 4000\n",
    "\n",
    "def get_data_from_db(groups):\n",
    "    target = []\n",
    "    data = []\n",
    "    for index, group in enumerate(groups):\n",
    "        limit = max_data_size // len(group)\n",
    "        conn = psycopg2.connect(dbname=psql_db_name, user=psql_user, host=psql_host)\n",
    "        cur = conn.cursor()\n",
    "        for owner_id in group:\n",
    "            table_name = psql_table_prefix + '_' + str(owner_id)\n",
    "            cur.execute(SQL(\"SELECT text FROM {} LIMIT %s;\").format(Identifier(table_name)), (limit, ))\n",
    "            rows = cur.fetchall()\n",
    "            for row in rows:        \n",
    "                data.append(row[0])\n",
    "            target += [index] * len(rows)\n",
    "    #for owner_id in owner_ids:\n",
    "    #    table_name = psql_table_prefix + '_' + str(owner_id)\n",
    "    #    cur.execute(SQL(\"SELECT COUNT(*) FROM {};\").format(Identifier(table_name)))\n",
    "    #    limit = min(limit, cur.fetchone()[0])\n",
    "    #target = []\n",
    "    #for i in range(0, len(owner_ids)):\n",
    "    #    target += [i] * limit\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "travel count: 3432\n",
      "animals count: 3107\n",
      "sport count: 3280\n",
      "style count: 2824\n",
      "train accuracy: 0.9415584415584416\n",
      "test accuracy: 0.8547807332854062\n",
      "'Кот' => animals\n",
      "'Бразилия страна' => travel\n",
      "'Леопард' => animals\n",
      "'самая счастливая собака в мире' => animals\n",
      "'Лев царь зверей.' => animals\n",
      "'Футболист сборной России' => sport\n",
      "'Мы недавно приехали с Бали.' => travel\n",
      "'Купил себе модный свитер' => style\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "categories = ['travel', 'animals', 'sport', 'style']\n",
    "data, target = get_data_from_db([[51045049, 47951388, 55045888], [115357087, 71785575, 53388683], \n",
    "                                 [48303580, 121344058, 32894860, 126967384, 160506183], [24396213, 43460592]])\n",
    "for idx, elem in enumerate(categories):\n",
    "    print(elem + ' count: ' + str(target.count(idx)))\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.33, random_state=42)\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(token_pattern=r\"(?u)\\b[а-яА-Яa-zA-Z]{3,}|\\B#[а-яА-Яa-zA-Z]{3,}\\b\")),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=100, tol=1e-3)),\n",
    "])\n",
    "text_clf.fit(data_train, target_train)\n",
    "predictTrain = text_clf.predict(data_train)\n",
    "predictTest = text_clf.predict(data_test)\n",
    "print(\"train accuracy:\", np.mean(predictTrain == target_train))\n",
    "print(\"test accuracy:\", np.mean(predictTest == target_test))\n",
    "\n",
    "docs_new = ['Кот', 'Бразилия страна',\n",
    "            'Леопард', 'самая счастливая собака в мире',\n",
    "            'Лев царь зверей.', \"Футболист сборной России\", \n",
    "            \"Мы недавно приехали с Бали.\", \"Купил себе модный свитер\"]\n",
    "predicted_test_sample = text_clf.predict(docs_new)\n",
    "\n",
    "\n",
    "\n",
    "for doc, category in zip(docs_new, predicted_test_sample):\n",
    "    print('%r => %s' % (doc, categories[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      travel       0.88      0.76      0.82      1128\n",
      "     animals       0.91      0.82      0.86      1049\n",
      "       sport       0.75      0.94      0.83      1059\n",
      "       style       0.93      0.91      0.92       937\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      4173\n",
      "   macro avg       0.87      0.86      0.86      4173\n",
      "weighted avg       0.86      0.85      0.86      4173\n",
      "\n",
      "[[860  50 202  16]\n",
      " [ 79 860  89  21]\n",
      " [ 17  19 998  25]\n",
      " [ 23  15  50 849]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(target_test, predictTest,\n",
    "    target_names=categories))\n",
    "print(metrics.confusion_matrix(target_test, predictTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8639934557298302\n",
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, iid=False, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(data_train, target_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
