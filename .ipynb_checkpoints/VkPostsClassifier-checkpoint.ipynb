{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "from psycopg2.sql import SQL, Identifier\n",
    "\n",
    "psql_db_name = 'text_classification_db'\n",
    "psql_table_prefix = 'vk_wall_posts'\n",
    "psql_user = 'postgres'\n",
    "psql_pass = '1'\n",
    "psql_host = '/var/run/postgresql/'\n",
    "max_data_size = 4000\n",
    "\n",
    "def get_data_from_db(groups):\n",
    "    target = []\n",
    "    data = []\n",
    "    for index, group in enumerate(groups):\n",
    "        limit = max_data_size // len(group)\n",
    "        conn = psycopg2.connect(dbname=psql_db_name, user=psql_user, password=psql_pass)\n",
    "        cur = conn.cursor()\n",
    "        for owner_id in group:\n",
    "            table_name = psql_table_prefix + '_' + str(owner_id)\n",
    "            cur.execute(SQL(\"SELECT text FROM {} LIMIT %s;\").format(Identifier(table_name)), (limit, ))\n",
    "            rows = cur.fetchall()\n",
    "            for row in rows:        \n",
    "                data.append(row[0])\n",
    "            target += [index] * len(rows)\n",
    "    #for owner_id in owner_ids:\n",
    "    #    table_name = psql_table_prefix + '_' + str(owner_id)\n",
    "    #    cur.execute(SQL(\"SELECT COUNT(*) FROM {};\").format(Identifier(table_name)))\n",
    "    #    limit = min(limit, cur.fetchone()[0])\n",
    "    #target = []\n",
    "    #for i in range(0, len(owner_ids)):\n",
    "    #    target += [i] * limit\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return data, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3431\n",
      "3107\n",
      "3280\n",
      "train accuracy: 0.9341745211310428\n",
      "test accuracy: 0.8697530864197531\n",
      "[[-1.10497962  0.24718458 -1.10593877]\n",
      " [-0.25837117 -1.10932048 -1.05108232]\n",
      " [-1.04908925 -0.25528403 -0.99516233]\n",
      " [-0.80410168  0.10395546 -1.34789398]\n",
      " [-0.78199122 -0.96159909 -0.81840848]\n",
      " [-0.99274445 -0.56527986 -1.01347254]\n",
      " [-1.27784829 -1.40149069  1.33657665]\n",
      " [-0.37291326 -0.90345218 -1.04289881]\n",
      " [-1.09410339 -0.24471993 -0.81728691]]\n",
      "'Кот' => animals\n",
      "'Бразилия страна' => travel\n",
      "'Леопард' => animals\n",
      "'самая счастливая собака в мире' => animals\n",
      "'Знаешь, Мэри, в моей голове звери.' => travel\n",
      "'Лев царь зверей.' => animals\n",
      "'Футболист сборной России' => sport\n",
      "'Мы недавно приехали с Бали.' => travel\n",
      "'Джус любит, когда ему чешут пузико' => animals\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "categories = ['travel', 'animals', 'sport', ]\n",
    "data, target = get_data_from_db([[51045049, 47951388, 55045888], [115357087, 71785575, 53388683], \n",
    "                                 [48303580, 121344058, 32894860, 126967384, 160506183]])\n",
    "for idx, elem in enumerate(categories):\n",
    "    print(target.count(idx))\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.33, random_state=42)\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(token_pattern=r\"(?u)\\b[а-яА-Яa-zA-Z]{3,}|\\B#[а-яА-Яa-zA-Z]{3,}\\b\")),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=100, tol=1e-3)),\n",
    "])\n",
    "text_clf.fit(data_train, target_train)\n",
    "predictTrain = text_clf.predict(data_train)\n",
    "predictTest = text_clf.predict(data_test)\n",
    "print(\"train accuracy:\", np.mean(predictTrain == target_train))\n",
    "print(\"test accuracy:\", np.mean(predictTest == target_test))\n",
    "\n",
    "docs_new = ['Кот', 'Бразилия страна',\n",
    "            'Леопард', 'самая счастливая собака в мире',\n",
    "           'Знаешь, Мэри, в моей голове звери.', 'Лев царь зверей.', \"Футболист сборной России\", \n",
    "            \"Мы недавно приехали с Бали.\", \"Джус любит, когда ему чешут пузико\"]\n",
    "predicted_test_sample = text_clf.predict(docs_new)\n",
    "\n",
    "#pred_proba = text_clf.predict_proba(docs_new)\n",
    "#print(pred_proba)\n",
    "\n",
    "dec_func = text_clf.decision_function(docs_new)\n",
    "print(dec_func)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted_test_sample):\n",
    "    print('%r => %s' % (doc, categories[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      travel       0.93      0.72      0.81      1142\n",
      "     animals       0.91      0.84      0.87      1031\n",
      "       sport       0.93      0.66      0.77      1092\n",
      "        food       0.65      0.97      0.78      1295\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      4560\n",
      "   macro avg       0.85      0.80      0.81      4560\n",
      "weighted avg       0.84      0.81      0.81      4560\n",
      "\n",
      "[[ 827   55   38  222]\n",
      " [  47  871   10  103]\n",
      " [   7   20  719  346]\n",
      " [  11   15    7 1262]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(target_test, predictTest,\n",
    "    target_names=categories))\n",
    "print(metrics.confusion_matrix(target_test, predictTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7990164738632656\n",
      "clf__alpha: 0.01\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, iid=False, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(data_train, target_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
